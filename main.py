import os
import joblib
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, f1_score, recall_score
from imblearn.over_sampling import SMOTE

from src.preprocess import prepare_dataset
from src.train_models import train_and_save_models
from src.regression_models import train_regression_models
from src.model_utils import get_model
from src.fuzzy_module import fuzzy_classify_fluoride

def main():
    print("üîπ Preprocessing & loading dataset...")

    data_path = "data/fluoride_data.csv"
    if not os.path.exists(data_path):
        print(f"‚ùå Dataset not found at {data_path}")
        return

    # ‚úÖ Preprocess dataset
    X, y, F_raw, df, features, target_col, scaler, encoder = prepare_dataset(data_path)
    print(f"‚úÖ Data loaded: X shape = {X.shape}, y shape = {y.shape}")

    # ‚úÖ Apply SMOTE
    print("\nüîπ Applying SMOTE oversampling...")
    smote = SMOTE(random_state=42)
    X_bal, y_bal = smote.fit_resample(X, y)
    print("Class distribution after SMOTE:")
    print(pd.Series(y_bal).value_counts(normalize=True))

    # ‚úÖ Split balanced data
    X_train, X_test, y_train, y_test = train_test_split(
        X_bal, y_bal, test_size=0.3, random_state=42, stratify=y_bal
    )

    # ‚úÖ Train classification models
    print("\nüöÄ Training classification models...")
    results, splits = train_and_save_models(X_bal, y_bal, scaler=scaler, encoder=encoder)
    X_train, X_test, y_train, y_test = splits


    print("‚úÖ Models trained and saved in /models folder")

   # ‚úÖ Train regression models
    print("\nüîπ Training Regression Models to predict actual Fluoride concentration...")
    reg_results = train_regression_models(X, df[target_col])

    # Fix: pick best regressor by r¬≤ score
    best_regressor_name = max(reg_results, key=lambda k: reg_results[k]['R2'])
    best_regressor_score = reg_results[best_regressor_name]['R2']

    print(f"üèÜ Best Regressor: {best_regressor_name} (R¬≤ = {best_regressor_score:.4f})")

    # Re-train the best regressor to predict fluoride
    reg_model = get_model(best_regressor_name)
    reg_model.fit(X, df[target_col])
    fluoride_preds = reg_model.predict(X)

    df["Predicted_Fluoride"] = fluoride_preds


    # ‚úÖ Apply fuzzy logic classification based on predictions
    print("\nüåç Regional Fluoride Fuzzy Safety Summary:")
    fuzzy_results = []
    for i in range(len(df)):
        location = df.get("Location", [f"Site_{i}"])[i]
        fluoride_value = df["Predicted_Fluoride"].iloc[i]
        fuzzy_label, fuzzy_score = fuzzy_classify_fluoride(fluoride_value)
        fuzzy_results.append((location, fluoride_value, fuzzy_label, fuzzy_score))

    fuzzy_df = pd.DataFrame(fuzzy_results, columns=["Location", "Fluoride (mg/L)", "Risk_Label", "Risk_Score"])
    print(fuzzy_df.head(10))    

    fuzzy_df.to_csv("results/fuzzy_fluoride_summary.csv", index=False)
    print("\n‚úÖ Fuzzy classification results saved to results/fuzzy_fluoride_summary.csv")

    # ---- GROUP BY STATE ----
    if "State" in df.columns:
        fuzzy_df["State"] = df["State"]

        state_summary = fuzzy_df.groupby("State").agg({
            "Fluoride (mg/L)": "mean",
            "Risk_Score": "mean",
            "Risk_Label": lambda x: x.value_counts().to_dict()
        })

        print("\nüìç STATE-WISE FUZZY SAFETY REPORT:")
        print(state_summary)

        state_summary.to_csv("results/state_wise_fuzzy_report.csv")
        from src.visualize_fuzzy_report import visualize_state_fuzzy_report
        visualize_state_fuzzy_report(state_summary)

    else:
        print("‚ö† State column not found ‚Äî cannot group fuzzy results.")


    # --- Model performance section ---
    print("\nüìä Class distribution (original):")
    print(pd.Series(y).value_counts(normalize=True))

    best_model_name = max(results, key=results.get)
    print(f"\nüèÜ Best Classifier: {best_model_name} (Accuracy = {results[best_model_name]:.4f})")

    model = get_model(best_model_name)
    model.fit(X_train, y_train)
    preds = model.predict(X_test)
    from src.visualize_ml_models import visualize_all_model_metrics

    model_dir = "models"
    results_dict = {}

    for model_name in results.keys():  # keys from accuracy results
        model_path = os.path.join(model_dir, f"{model_name}.pkl")
        if os.path.exists(model_path):
            model = joblib.load(model_path)
            preds = model.predict(X_test)
            results_dict[model_name] = (y_test, preds)
        else:
            print(f"‚ö† Model file not found: {model_path}")

    visualize_all_model_metrics(results_dict)


    print("\nüìà Classification Report:")
    print(classification_report(y_test, preds))
    print("\nConfusion Matrix:")
    print(confusion_matrix(y_test, preds))

    # Additional metrics
    macro_f1 = f1_score(y_test, preds, average='macro')
    macro_recall = recall_score(y_test, preds, average='macro')
    print(f"\nMacro F1 Score: {macro_f1:.4f}")
    print(f"Macro Recall: {macro_recall:.4f}")

if __name__ == "__main__":
    os.makedirs("results", exist_ok=True)
    main()
